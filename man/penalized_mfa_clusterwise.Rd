% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/penalized_mfa_clusterwise.R
\name{penalized_mfa_clusterwise}
\alias{penalized_mfa_clusterwise}
\alias{pmfa_cluster}
\title{Penalized MFA with Clusterwise Spatial Smoothness Constraints}
\usage{
penalized_mfa_clusterwise(
  data_list,
  coords_list,
  ncomp = 2L,
  lambda = 1,
  adjacency_opts = list(),
  max_iter = 10L,
  nsteps_inner = 1L,
  learning_rate = 0.01,
  optimizer = c("gradient", "adam"),
  beta1 = 0.9,
  beta2 = 0.999,
  adam_epsilon = 1e-08,
  tol_obj = 1e-07,
  tol_inner = NULL,
  verbose = FALSE,
  preproc = NULL,
  memory_budget_mb = 1024,
  normalized_laplacian = TRUE
)

pmfa_cluster(
  data_list,
  coords_list,
  ncomp = 2L,
  lambda = 1,
  adjacency_opts = list(),
  max_iter = 10L,
  nsteps_inner = 1L,
  learning_rate = 0.01,
  optimizer = c("gradient", "adam"),
  beta1 = 0.9,
  beta2 = 0.999,
  adam_epsilon = 1e-08,
  tol_obj = 1e-07,
  tol_inner = NULL,
  verbose = FALSE,
  preproc = NULL,
  memory_budget_mb = 1024,
  normalized_laplacian = TRUE
)
}
\arguments{
\item{data_list}{A list of length \eqn{S}, each \eqn{n_s \times k_s}. Assumed column-centered.}

\item{coords_list}{A list of length \eqn{S}, each \eqn{k_s \times 3} of cluster coords.}

\item{ncomp}{Number of latent components per block.}

\item{lambda}{Nonnegative penalty weight for the spatial smoothness constraint.}

\item{adjacency_opts}{A list passed to \code{\link{spatial_constraints}} for adjacency construction.}

\item{max_iter}{Outer loop (BCD) steps.}

\item{nsteps_inner}{Inner steps (gradient or Adam) per block update.}

\item{learning_rate}{Base step size.}

\item{optimizer}{"gradient" or "adam".}

\item{beta1, beta2}{Adam hyperparameters (defaults: 0.9, 0.999).}

\item{adam_epsilon}{Small constant for Adam denominator (default: 1e-8).}

\item{tol_obj}{Numeric tolerance for outer loop objective relative change (default: 1e-7).}

\item{tol_inner}{Tolerance for stopping block updates if \eqn{\|V_{new}-V_{old}\|_F < tol_inner}.}

\item{verbose}{If \code{TRUE}, prints iteration logs.}

\item{preproc}{Optional preprocessing for each block. Can be NULL (default), a single `prepper` object (applied independently to each block), or a list of `prepper` objects (one per block).}

\item{memory_budget_mb}{Numeric (default 1024). Maximum memory (in MB) allocated per block for pre-computing `XtX`. If exceeded, gradient is computed on-the-fly, and objective uses a different formula.}

\item{normalized_laplacian}{Logical (default TRUE). If TRUE, uses normalized Laplacian L_sym = D^{-1/2} L D^{-1/2} for scale-free smoothness.}
}
\value{
A `multiblock_projector` object with class `"penalized_mfa_clusterwise"`.
  The base projector stores the concatenated loading matrix in `v`, the
  block mapping in `block_indices`, and a pass-through preprocessor in `preproc`.
  Additional elements accessible via `$` include:
  * `Sadj`          -- graph Laplacian used for the smoothness penalty.
  * `LV`            -- product `Sadj %*% v` from the final iteration.
  * `obj_values`    -- objective value at each outer iteration.
  * `lambda`        -- smoothness penalty weight.
  * `precompute_info` -- logical vector indicating which blocks used precomputed gradients.
  * `iterations_run` -- number of iterations actually performed.
  * `V_list`        -- list of per-block loading matrices.
}
\description{
A penalized MFA-like method for multi-subject cluster data, where each subject
\eqn{X_s \in \mathbb{R}^{n_s \times k_s}} has \code{k_s} clusters (columns).
Cluster coordinates (\code{coords_list}) are used to build a graph structure,
and the penalty encourages smoothness of loadings \eqn{V_s} across connected
clusters using the graph Laplacian. Assumes data blocks \code{X_s} are column-centered.

We solve:
\deqn{
  \min_{\{V_s\}} \sum_{s=1}^S \|X_s - X_s V_s V_s^\top\|_F^2
  + \lambda \,\mathrm{trace}(V^\top L\,V),
}
where \(\mathbf{V}\) is the row-wise concatenation of \(\{\mathbf{V}_s\}\) and
\eqn{L = D - A} is the graph Laplacian derived from the adjacency matrix \eqn{A}
constructed by \code{spatial_constraints}. Minimizing this term encourages
loadings \eqn{v_i} and \eqn{v_j} to be similar if clusters \eqn{i} and \eqn{j}
are connected (\eqn{A_{ij}=1}).

**Engineering Improvements Implemented:**
\itemize{
  \item **Mathematical**: Normalized Laplacian default (scale-free smoothness), lambda=0 optimization skips
  \item **Numerical**: Sparse XtX matrices, in-block QR retraction, `pracma::orth()` for speed
  \item **Stability**: Variable-rank V_s per block, robust parameter validation, Adam state management
  \item **Architecture**: Modular helper functions, `cli` package logging, consolidated parameter validation
  \item **Memory**: Memory budget checks for large blocks, efficient gradient computation strategies
  \item **API**: Shorter `pmfa_cluster()` alias, consistent naming conventions
}
}
