<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0"><title>Penalized Multiple Factor Analysis (MFA) — penalized_mfa • muscal</title><!-- jquery --><script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.7.1/jquery.min.js" integrity="sha512-v2CJ7UaYy4JwqLDIrZUI/4hqeoQieOmAZNXBeQyjo21dadnwR+8ZaIJVT8EE2iyI61OV8e6M8PP2/4hpQINQ/g==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><!-- Bootstrap --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous"><script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script><!-- bootstrap-toc --><link rel="stylesheet" href="../bootstrap-toc.css"><script src="../bootstrap-toc.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous"><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet"><script src="../pkgdown.js"></script><meta property="og:title" content="Penalized Multiple Factor Analysis (MFA) — penalized_mfa"><meta property="og:description" content="This function implements a penalized Multiple Factor Analysis decomposition that
encourages similarity among block-specific loading matrices. The method uses
block-coordinate descent (BCD) with Riemannian optimization on the Stiefel manifold
to estimate orthonormal loading matrices for each data block while applying a
regularization penalty that promotes structural similarity across blocks."><!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]--></head><body data-spy="scroll" data-target="#toc">


    <div class="container template-reference-topic">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">muscal</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="">0.1.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav"><li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" data-bs-toggle="dropdown" aria-expanded="false">
    Articles

    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu"><li>
      <a href="../articles/linked_mfa.html">Linked Multiple Factor Analysis</a>
    </li>
    <li>
      <a href="../articles/mfa.html">Multiple Factor Analysis</a>
    </li>
  </ul></li>
      </ul><ul class="nav navbar-nav navbar-right"></ul></div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->



      </header><div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Penalized Multiple Factor Analysis (MFA)</h1>

    <div class="hidden name"><code>penalized_mfa.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>This function implements a penalized Multiple Factor Analysis decomposition that
encourages similarity among block-specific loading matrices. The method uses
block-coordinate descent (BCD) with Riemannian optimization on the Stiefel manifold
to estimate orthonormal loading matrices for each data block while applying a
regularization penalty that promotes structural similarity across blocks.</p>
    </div>

    <div id="ref-usage">
    <div class="sourceCode"><pre class="sourceCode r"><code><span><span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">data</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for class 'list'</span></span>
<span><span class="fu">penalized_mfa</span><span class="op">(</span></span>
<span>  <span class="va">data</span>,</span>
<span>  ncomp <span class="op">=</span> <span class="fl">2</span>,</span>
<span>  lambda <span class="op">=</span> <span class="fl">1</span>,</span>
<span>  penalty_method <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"projection"</span>, <span class="st">"pairwise"</span>, <span class="st">"global_mean"</span><span class="op">)</span>,</span>
<span>  max_iter <span class="op">=</span> <span class="fl">10</span>,</span>
<span>  nsteps_inner <span class="op">=</span> <span class="fl">5</span>,</span>
<span>  learning_rate <span class="op">=</span> <span class="fl">0.01</span>,</span>
<span>  optimizer <span class="op">=</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="st">"adam"</span>, <span class="st">"gradient"</span><span class="op">)</span>,</span>
<span>  preproc <span class="op">=</span> <span class="fu">multivarious</span><span class="fu">::</span><span class="fu"><a href="https://bbuchsbaum.github.io/multivarious/reference/center.html" class="external-link">center</a></span><span class="op">(</span><span class="op">)</span>,</span>
<span>  beta1 <span class="op">=</span> <span class="fl">0.9</span>,</span>
<span>  beta2 <span class="op">=</span> <span class="fl">0.999</span>,</span>
<span>  adam_epsilon <span class="op">=</span> <span class="fl">1e-08</span>,</span>
<span>  tol_obj <span class="op">=</span> <span class="fl">1e-07</span>,</span>
<span>  tol_inner <span class="op">=</span> <span class="cn">NULL</span>,</span>
<span>  compute_consensus <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  verbose <span class="op">=</span> <span class="cn">FALSE</span>,</span>
<span>  <span class="va">...</span></span>
<span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for class 'multiblock'</span></span>
<span><span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">data</span>, <span class="va">...</span><span class="op">)</span></span>
<span></span>
<span><span class="co"># S3 method for class 'multidesign'</span></span>
<span><span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">data</span>, <span class="va">subject</span>, <span class="va">...</span><span class="op">)</span></span></code></pre></div>
    </div>

    <div id="arguments">
    <h2>Arguments</h2>


<dl><dt id="arg-data">data<a class="anchor" aria-label="anchor" href="#arg-data"></a></dt>
<dd><p>A list of matrices, a `multiblock` object, or a `multidesign` object.
For lists, each element should be a numeric matrix with the same number of rows
(observations). Columns represent features and can differ across blocks.</p></dd>


<dt id="arg--">...<a class="anchor" aria-label="anchor" href="#arg--"></a></dt>
<dd><p>Additional arguments passed to methods. Currently unused but included
for S3 method consistency.</p></dd>


<dt id="arg-ncomp">ncomp<a class="anchor" aria-label="anchor" href="#arg-ncomp"></a></dt>
<dd><p>Integer number of latent components to extract (default: 2). This is
automatically capped at the minimum number of columns across all blocks after
preprocessing. Must be at least 1.</p></dd>


<dt id="arg-lambda">lambda<a class="anchor" aria-label="anchor" href="#arg-lambda"></a></dt>
<dd><p>Non-negative scalar controlling the strength of the penalty (default: 1).
Larger values encourage more similarity among block loadings. When `lambda = 0`,
the method reduces to independent PCA on each block. Typical range: 0 to 10.</p></dd>


<dt id="arg-penalty-method">penalty_method<a class="anchor" aria-label="anchor" href="#arg-penalty-method"></a></dt>
<dd><p>Character string specifying the penalty type (default: "projection").
Options are:</p><ul><li><p><code>"projection"</code>: Rotation-invariant penalty on projection matrices (recommended)</p></li>
<li><p><code>"pairwise"</code>: Pairwise Euclidean distances between loading matrices</p></li>
<li><p><code>"global_mean"</code>: Distance from mean loading matrix</p></li>
</ul></dd>


<dt id="arg-max-iter">max_iter<a class="anchor" aria-label="anchor" href="#arg-max-iter"></a></dt>
<dd><p>Maximum number of outer block-coordinate descent iterations (default: 10).
Typical range: 10 to 100. More iterations allow better convergence but increase
computation time.</p></dd>


<dt id="arg-nsteps-inner">nsteps_inner<a class="anchor" aria-label="anchor" href="#arg-nsteps-inner"></a></dt>
<dd><p>Number of gradient update steps per block in each outer iteration
(default: 5). Higher values perform more thorough optimization of each block before
moving to the next. Typical range: 1 to 20.</p></dd>


<dt id="arg-learning-rate">learning_rate<a class="anchor" aria-label="anchor" href="#arg-learning-rate"></a></dt>
<dd><p>Step size for the optimizer (default: 0.01). Controls how far
to move in the gradient direction. Too large may cause divergence; too small slows
convergence. Typical range for gradient descent: 0.001 to 0.1. Adam is less
sensitive to this parameter.</p></dd>


<dt id="arg-optimizer">optimizer<a class="anchor" aria-label="anchor" href="#arg-optimizer"></a></dt>
<dd><p>Character string specifying the optimization algorithm (default: "adam").
Options are:</p><ul><li><p><code>"adam"</code>: Adaptive Moment Estimation with momentum and adaptive learning rates</p></li>
<li><p><code>"gradient"</code>: Standard gradient descent with fixed learning rate</p></li>
</ul><p>Adam is generally more robust and converges faster with default settings.</p></dd>


<dt id="arg-preproc">preproc<a class="anchor" aria-label="anchor" href="#arg-preproc"></a></dt>
<dd><p>A preprocessing specification (default: `multivarious::center()`).
Can be:</p><ul><li><p>A single `pre_processor` object applied to all blocks</p></li>
<li><p>A list of `pre_processor` objects (one per block)</p></li>
<li><p><code>NULL</code> for no preprocessing (identity transformation)</p></li>
</ul><p>Common options: `center()`, `standardize()`, `pass()` (no-op).</p></dd>


<dt id="arg-beta-">beta1<a class="anchor" aria-label="anchor" href="#arg-beta-"></a></dt>
<dd><p>Adam hyperparameter for first moment decay (default: 0.9). Controls
the exponential decay rate for gradient moving average. Typical range: 0.8 to 0.95.
Only used when `optimizer = "adam"`.</p></dd>


<dt id="arg-beta-">beta2<a class="anchor" aria-label="anchor" href="#arg-beta-"></a></dt>
<dd><p>Adam hyperparameter for second moment decay (default: 0.999). Controls
the exponential decay rate for squared gradient moving average. Typical range:
0.99 to 0.9999. Only used when `optimizer = "adam"`.</p></dd>


<dt id="arg-adam-epsilon">adam_epsilon<a class="anchor" aria-label="anchor" href="#arg-adam-epsilon"></a></dt>
<dd><p>Small constant added to denominator in Adam for numerical
stability (default: 1e-8). Prevents division by zero. Only used when
`optimizer = "adam"`.</p></dd>


<dt id="arg-tol-obj">tol_obj<a class="anchor" aria-label="anchor" href="#arg-tol-obj"></a></dt>
<dd><p>Numeric tolerance for outer loop convergence based on relative
change in objective function (default: 1e-7). Smaller values require more precise
convergence. Typical range: 1e-8 to 1e-5.</p></dd>


<dt id="arg-tol-inner">tol_inner<a class="anchor" aria-label="anchor" href="#arg-tol-inner"></a></dt>
<dd><p>Optional numeric tolerance for inner loop convergence based on
Frobenius norm of change in loading matrix (default: NULL, no early stopping).
When specified, inner loop stops if \(\|\mathbf{V}_i^{\text{new}} - \mathbf{V}_i\|_F &lt; \text{tol_inner}\).</p></dd>


<dt id="arg-compute-consensus">compute_consensus<a class="anchor" aria-label="anchor" href="#arg-compute-consensus"></a></dt>
<dd><p>Logical indicating whether to compute a consensus loading
matrix (default: FALSE). Only computed when all blocks have the same number of
features after preprocessing. The consensus is the orthonormalized sum of
block-specific loadings.</p></dd>


<dt id="arg-verbose">verbose<a class="anchor" aria-label="anchor" href="#arg-verbose"></a></dt>
<dd><p>Logical indicating whether to print iteration progress (default: FALSE).
When TRUE, displays objective values and relative changes at each iteration using
the `cli` package.</p></dd>


<dt id="arg-subject">subject<a class="anchor" aria-label="anchor" href="#arg-subject"></a></dt>
<dd><p>Required for `multidesign` method: the name (unquoted) of the subject
variable used to split data into blocks. Each subject's data becomes a separate
block in the analysis.</p></dd>

</dl></div>
    <div id="value">
    <h2>Value</h2>
    <p>A `multiblock_projector` object of class `penalized_mfa` with the following components:</p><dl><dt><code>v</code></dt>
<dd><p>Concatenated loading matrix (total_features × ncomp) formed by
      vertically stacking all block-specific loading matrices.</p></dd>

    <dt><code>preproc</code></dt>
<dd><p>A `concat_pre_processor` object containing the preprocessing
      transformations applied to each block. Can be used to transform new data.</p></dd>

    <dt><code>block_indices</code></dt>
<dd><p>A named list indicating which rows of `v` correspond
      to each block. Each element is an integer vector of row indices.</p></dd>


</dl><p>Additional information is stored as attributes:</p><dl><dt><code>V_list</code></dt>
<dd><p>List of length S containing the final orthonormal loading
      matrices for each block. Each element is a (p_i × ncomp) matrix.</p></dd>

    <dt><code>obj_values</code></dt>
<dd><p>Numeric vector of objective function values at each
      iteration, including the initial value. Length is (iterations_run + 1).</p></dd>

    <dt><code>consensus</code></dt>
<dd><p>The consensus loading matrix (p\_post × ncomp) if
      `compute_consensus=TRUE`, otherwise `NULL`. This is the orthonormalized
      average of block loadings over blocks with matching feature dimension.</p></dd>

    <dt><code>lambda</code></dt>
<dd><p>The penalty strength used in the optimization.</p></dd>

    <dt><code>penalty_method</code></dt>
<dd><p>Character string indicating the penalty type used.
      May be "none" if penalty was disabled due to inconsistent block dimensions.</p></dd>

    <dt><code>iterations_run</code></dt>
<dd><p>Integer indicating how many outer iterations were
      completed before convergence or reaching max_iter.</p></dd>


</dl></div>
    <div id="details">
    <h2>Details</h2>
    <p>## Optimization Problem</p>
<p>For \(S\) data blocks \(\mathbf{X}_i \in \mathbb{R}^{n \times p_i}\) (where
\(i = 1, \ldots, S\)), the method estimates loading matrices
\(\mathbf{V}_i \in \mathbb{R}^{p_i \times k}\) with orthonormal columns
(\(\mathbf{V}_i^\top \mathbf{V}_i = \mathbf{I}_k\)) by minimizing:</p>
<p>$$
  \min_{\{V_i\}} \sum_{i=1}^S \|\mathbf{X}_i - \mathbf{X}_i \mathbf{V}_i \mathbf{V}_i^\top\|_F^2
  \;+\; \lambda \,\text{Penalty}(\{\mathbf{V}_i\})
$$</p>
<p>The first term is the reconstruction error (sum of squared residuals) for each block,
and the second term is a penalty that encourages similarity among the loading matrices.</p>
<p>## Penalty Options</p>
<p>Three penalty formulations are available:</p>
<dl><dt><strong>Projection</strong> (default, rotation-invariant):</dt>
<dd><p>$$\sum_{i=1}^S \|\mathbf{P}_i - \bar{\mathbf{P}}\|_F^2$$
    where \(\mathbf{P}_i = \mathbf{V}_i \mathbf{V}_i^\top\) is the projection
    matrix for block \(i\) and \(\bar{\mathbf{P}} = \frac{1}{S}\sum_{i=1}^S \mathbf{P}_i\).
    This penalty is invariant to rotations of the loading matrices and is recommended
    when the orientation of the latent space is arbitrary.</p></dd>

  <dt><strong>Global Mean</strong> (not rotation-invariant):</dt>
<dd><p>$$\sum_{i=1}^S \|\mathbf{V}_i - \bar{\mathbf{V}}\|_F^2$$
    where \(\bar{\mathbf{V}} = \frac{1}{S}\sum_{i=1}^S \mathbf{V}_i\). This directly
    penalizes Euclidean distance from the mean loading matrix. Computationally simpler
    than pairwise but not rotation-invariant.</p></dd>

  <dt><strong>Pairwise</strong> (not rotation-invariant):</dt>
<dd><p>$$\sum_{i &lt; j} \|\mathbf{V}_i - \mathbf{V}_j\|_F^2$$
    This penalizes all pairwise Euclidean distances between loading matrices.
    Equivalent to global mean up to a scaling factor but conceptually different.</p></dd>


</dl><p>## Optimization Algorithm</p>
<p>The algorithm uses block-coordinate descent with Riemannian gradient descent on
the Stiefel manifold:</p>
<p>1. **Outer loop** (max_iter iterations): Cycles through all blocks
2. **Inner loop** (nsteps_inner steps per block): Updates each block's loading matrix
3. **Gradient computation**: Combines reconstruction gradient and penalty gradient
4. **Tangent space projection**: Projects gradient onto Stiefel manifold tangent space
5. **Update step**: Uses either gradient descent or Adam optimizer
6. **Retraction**: Re-orthonormalizes via QR decomposition to maintain manifold constraint</p>
<p>The Stiefel manifold constraint ensures \(\mathbf{V}_i^\top \mathbf{V}_i = \mathbf{I}_k\)
at all iterations, which is critical for identifiability and interpretability.</p>
<p>## Convergence Criteria</p>
<p>The outer loop stops when the relative change in the objective function falls below
`tol_obj`:
$$\frac{|f^{(t+1)} - f^{(t)}|}{|f^{(t)}| + \epsilon} &lt; \text{tol_obj}$$</p>
<p>Optionally, the inner loop can stop early if the Frobenius norm of the change in
\(\mathbf{V}_i\) falls below `tol_inner`.</p>
<p>## Preprocessing</p>
<p>Data preprocessing is handled via the `multivarious` package. Common preprocessing
steps include centering (default) and scaling. Each block can have its own
preprocessor, or a single preprocessor can be applied to all blocks. Preprocessing
is "learned" from the input data and stored in the result object for later use on
new data.</p>
<p>## Consensus Loading Matrix</p>
<p>When `compute_consensus = TRUE` and blocks have equal feature dimensions, a consensus
loading matrix is computed by orthonormalizing the sum of block-specific loadings:
$$\mathbf{V}_{\text{consensus}} = \text{orth}\left(\sum_{i=1}^S \mathbf{V}_i\right)$$</p>
<p>This provides a single "average" loading matrix that summarizes the common structure.</p>
    </div>
    <div id="input-types">
    <h2>Input types</h2>


<p>The function supports three input types via S3 methods:</p><dl><dt><code>list</code></dt>
<dd><p>A list of numeric matrices, each representing a data block</p></dd>

  <dt><code>multiblock</code></dt>
<dd><p>A multiblock object from the <code>multivarious</code> package</p></dd>

  <dt><code>multidesign</code></dt>
<dd><p>A multidesign object where each subject is treated as a separate block</p></dd>


</dl></div>

    <div id="ref-examples">
    <h2>Examples</h2>
    <div class="sourceCode"><pre class="sourceCode r"><code><span class="r-in"><span><span class="kw">if</span> <span class="op">(</span><span class="cn">FALSE</span><span class="op">)</span> <span class="op">{</span> <span class="co"># \dontrun{</span></span></span>
<span class="r-in"><span><span class="co"># Example 1: Basic usage with simulated data</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/Random.html" class="external-link">set.seed</a></span><span class="op">(</span><span class="fl">123</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">data_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="fl">1</span><span class="op">:</span><span class="fl">3</span>, <span class="kw">function</span><span class="op">(</span><span class="va">i</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/matrix.html" class="external-link">matrix</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/stats/Normal.html" class="external-link">rnorm</a></span><span class="op">(</span><span class="fl">100</span><span class="op">)</span>, <span class="fl">10</span>, <span class="fl">10</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res</span> <span class="op">&lt;-</span> <span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">data_list</span>, ncomp<span class="op">=</span><span class="fl">2</span>, lambda<span class="op">=</span><span class="fl">1</span>, penalty_method<span class="op">=</span><span class="st">"projection"</span>,</span></span>
<span class="r-in"><span>                     optimizer<span class="op">=</span><span class="st">"adam"</span>, max_iter<span class="op">=</span><span class="fl">50</span>, verbose<span class="op">=</span><span class="cn">TRUE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">res</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Access block-specific loadings</span></span></span>
<span class="r-in"><span><span class="va">V_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">res</span>, <span class="st">"V_list"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/base/print.html" class="external-link">print</a></span><span class="op">(</span><span class="va">V_list</span><span class="op">[[</span><span class="fl">1</span><span class="op">]</span><span class="op">]</span><span class="op">)</span>  <span class="co"># Loadings for first block</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Plot convergence</span></span></span>
<span class="r-in"><span><span class="va">obj_vals</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">res</span>, <span class="st">"obj_values"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="fu"><a href="https://rdrr.io/r/graphics/plot.default.html" class="external-link">plot</a></span><span class="op">(</span><span class="va">obj_vals</span>, type<span class="op">=</span><span class="st">'b'</span>, xlab<span class="op">=</span><span class="st">'Iteration'</span>, ylab<span class="op">=</span><span class="st">'Objective'</span>,</span></span>
<span class="r-in"><span>     main<span class="op">=</span><span class="st">'Convergence of Penalized MFA'</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Example 2: With consensus and custom preprocessing</span></span></span>
<span class="r-in"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://bbuchsbaum.github.io/multivarious/" class="external-link">multivarious</a></span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res2</span> <span class="op">&lt;-</span> <span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">data_list</span>, ncomp<span class="op">=</span><span class="fl">3</span>, lambda<span class="op">=</span><span class="fl">2</span>,</span></span>
<span class="r-in"><span>                      preproc<span class="op">=</span><span class="fu"><a href="https://bbuchsbaum.github.io/multivarious/reference/standardize.html" class="external-link">standardize</a></span><span class="op">(</span><span class="op">)</span>,  <span class="co"># Center and scale</span></span></span>
<span class="r-in"><span>                      compute_consensus<span class="op">=</span><span class="cn">TRUE</span>,</span></span>
<span class="r-in"><span>                      verbose<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">consensus_loadings</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">res2</span>, <span class="st">"consensus"</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Example 3: Comparing penalty methods</span></span></span>
<span class="r-in"><span><span class="va">res_proj</span> <span class="op">&lt;-</span> <span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">data_list</span>, ncomp<span class="op">=</span><span class="fl">2</span>, lambda<span class="op">=</span><span class="fl">1</span>, penalty_method<span class="op">=</span><span class="st">"projection"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res_mean</span> <span class="op">&lt;-</span> <span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">data_list</span>, ncomp<span class="op">=</span><span class="fl">2</span>, lambda<span class="op">=</span><span class="fl">1</span>, penalty_method<span class="op">=</span><span class="st">"global_mean"</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res_pair</span> <span class="op">&lt;-</span> <span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">data_list</span>, ncomp<span class="op">=</span><span class="fl">2</span>, lambda<span class="op">=</span><span class="fl">1</span>, penalty_method<span class="op">=</span><span class="st">"pairwise"</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Example 4: Lambda selection via objective values</span></span></span>
<span class="r-in"><span><span class="va">lambdas</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/c.html" class="external-link">c</a></span><span class="op">(</span><span class="fl">0</span>, <span class="fl">0.1</span>, <span class="fl">0.5</span>, <span class="fl">1</span>, <span class="fl">2</span>, <span class="fl">5</span>, <span class="fl">10</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">results</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/lapply.html" class="external-link">lapply</a></span><span class="op">(</span><span class="va">lambdas</span>, <span class="kw">function</span><span class="op">(</span><span class="va">lam</span><span class="op">)</span> <span class="op">{</span></span></span>
<span class="r-in"><span>  <span class="va">fit</span> <span class="op">&lt;-</span> <span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">data_list</span>, ncomp<span class="op">=</span><span class="fl">2</span>, lambda<span class="op">=</span><span class="va">lam</span>, verbose<span class="op">=</span><span class="cn">FALSE</span><span class="op">)</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span>lambda<span class="op">=</span><span class="va">lam</span>, final_obj<span class="op">=</span><span class="fu"><a href="https://rdrr.io/r/utils/head.html" class="external-link">tail</a></span><span class="op">(</span><span class="fu"><a href="https://rdrr.io/r/base/attr.html" class="external-link">attr</a></span><span class="op">(</span><span class="va">fit</span>, <span class="st">"obj_values"</span><span class="op">)</span>, <span class="fl">1</span><span class="op">)</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Example 5: Using with multiblock object</span></span></span>
<span class="r-in"><span><span class="va">mb</span> <span class="op">&lt;-</span> <span class="fu">multiblock</span><span class="op">(</span><span class="va">data_list</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res_mb</span> <span class="op">&lt;-</span> <span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">mb</span>, ncomp<span class="op">=</span><span class="fl">2</span>, lambda<span class="op">=</span><span class="fl">1</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Example 6: Different preprocessors per block</span></span></span>
<span class="r-in"><span><span class="va">preproc_list</span> <span class="op">&lt;-</span> <span class="fu"><a href="https://rdrr.io/r/base/list.html" class="external-link">list</a></span><span class="op">(</span></span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://bbuchsbaum.github.io/multivarious/reference/center.html" class="external-link">center</a></span><span class="op">(</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://bbuchsbaum.github.io/multivarious/reference/standardize.html" class="external-link">standardize</a></span><span class="op">(</span><span class="op">)</span>,</span></span>
<span class="r-in"><span>  <span class="fu"><a href="https://bbuchsbaum.github.io/multivarious/reference/pass.html" class="external-link">pass</a></span><span class="op">(</span><span class="op">)</span>  <span class="co"># No preprocessing for third block</span></span></span>
<span class="r-in"><span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="va">res_custom</span> <span class="op">&lt;-</span> <span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">data_list</span>, ncomp<span class="op">=</span><span class="fl">2</span>, lambda<span class="op">=</span><span class="fl">1</span>,</span></span>
<span class="r-in"><span>                            preproc<span class="op">=</span><span class="va">preproc_list</span><span class="op">)</span></span></span>
<span class="r-in"><span></span></span>
<span class="r-in"><span><span class="co"># Example 7: Gradient descent instead of Adam</span></span></span>
<span class="r-in"><span><span class="va">res_gd</span> <span class="op">&lt;-</span> <span class="fu">penalized_mfa</span><span class="op">(</span><span class="va">data_list</span>, ncomp<span class="op">=</span><span class="fl">2</span>, lambda<span class="op">=</span><span class="fl">1</span>,</span></span>
<span class="r-in"><span>                        optimizer<span class="op">=</span><span class="st">"gradient"</span>,</span></span>
<span class="r-in"><span>                        learning_rate<span class="op">=</span><span class="fl">0.001</span>,</span></span>
<span class="r-in"><span>                        max_iter<span class="op">=</span><span class="fl">100</span><span class="op">)</span></span></span>
<span class="r-in"><span><span class="op">}</span> <span class="co"># }</span></span></span>
<span class="r-in"><span></span></span>
</code></pre></div>
    </div>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top"><h2 data-toc-skip>Contents</h2>
    </nav></div>
</div>


      <footer><div class="copyright">
  <p></p><p>Developed by Bradley Buchsbaum.</p>
</div>

<div class="pkgdown">
  <p></p><p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.2.0.</p>
</div>

      </footer></div>






  </body></html>

